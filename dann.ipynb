{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/VIU/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import sys\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff8cc6e0110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#constants and hyperparameters\n",
    "# device = 'cpu'\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr = 1e-3\n",
    "batch_size = 16\n",
    "image_size = 28\n",
    "n_epoch = 100\n",
    "manual_seed = random.randint(1, 10000)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cataracts_data_dir = \"../../data/final_cataracts\"\n",
    "cataracts_train_dir = os.path.join(cataracts_data_dir, 'train')\n",
    "cataracts_val_dir = os.path.join(cataracts_data_dir, 'val')\n",
    "test_dir = os.path.join(cataracts_data_dir, 'test')\n",
    "\n",
    "d99_balanced_datadir = \"../../data/final_d99/\"\n",
    "d99_balanced_train_dir = os.path.join(d99_balanced_datadir, 'train')\n",
    "d99_balanced_val_dir = os.path.join(d99_balanced_datadir, 'val')\n",
    "d99_balanced_test_dir = os.path.join(d99_balanced_datadir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5726915, 0.35134485, 0.20473212], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5726915, 0.35134485, 0.20473212], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5726915, 0.35134485, 0.20473212], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(cataracts_data_dir,x),data_transforms[x]) for x in ['train','val','test']}\n",
    "\n",
    "cataracts_dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "                for x in ['train','val','test']\n",
    "}\n",
    "\n",
    "cataracts_dataset_sizes = {x: len(image_datasets[x]) for x in ['train','val','test']}\n",
    "cataracts_class_names = image_datasets['train'].classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_transforms99 = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.46083382, 0.34022495, 0.3280154], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.46083382, 0.34022495, 0.3280154], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.46083382, 0.34022495, 0.3280154], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets99_balanced = {x: datasets.ImageFolder(os.path.join(d99_balanced_datadir,x),data_transforms99[x]) for x in ['train','val','test']}\n",
    "\n",
    "d99_balanced_dataloaders= {x: torch.utils.data.DataLoader(image_datasets99_balanced[x], batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "                for x in ['train','val','test']\n",
    "}\n",
    "\n",
    "d99_balanced_dataset_sizes = {x: len(image_datasets99_balanced[x]) for x in ['train','val','test']}\n",
    "d99_balanced_class_names = image_datasets99_balanced['train'].classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, class_names_len, pretrained_weights=''):\n",
    "        super(CNNModel, self).__init__()\n",
    "        if pretrained_weights!='':\n",
    "            self.feature = models.resnet50(pretrained=False)\n",
    "            self.feature.load_state_dict(torch.load(pretrained_weights),strict=False)\n",
    "        else:\n",
    "            # self.feature = models.resnet18(pretrained=True)\n",
    "            self.feature = models.resnet50(pretrained=True)\n",
    "\n",
    "        self.in_features = self.feature.fc.in_features\n",
    "        self.feature.fc = nn.Identity()\n",
    "        # self.feature = nn.Sequential()\n",
    "        # self.feature.add_module('f_conv1', nn.Conv2d(3, 64, kernel_size=5))\n",
    "        # self.feature.add_module('f_bn1', nn.BatchNorm2d(64))\n",
    "        # self.feature.add_module('f_pool1', nn.MaxPool2d(2))\n",
    "        # self.feature.add_module('f_relu1', nn.ReLU(True))\n",
    "        # self.feature.add_module('f_conv2', nn.Conv2d(64, 50, kernel_size=5))\n",
    "        # self.feature.add_module('f_bn2', nn.BatchNorm2d(50))\n",
    "        # self.feature.add_module('f_drop1', nn.Dropout2d())\n",
    "        # self.feature.add_module('f_pool2', nn.MaxPool2d(2))\n",
    "        # self.feature.add_module('f_relu2', nn.ReLU(True))\n",
    "\n",
    "        self.class_classifier = nn.Sequential()\n",
    "        self.class_classifier.add_module('c_fc1', nn.Linear(self.in_features, 100))\n",
    "        self.class_classifier.add_module('c_bn1', nn.BatchNorm1d(100))\n",
    "        self.class_classifier.add_module('c_relu1', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_drop1', nn.Dropout())\n",
    "        self.class_classifier.add_module('c_fc2', nn.Linear(100, 100))\n",
    "        self.class_classifier.add_module('c_bn2', nn.BatchNorm1d(100))\n",
    "        self.class_classifier.add_module('c_relu2', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_fc3', nn.Linear(100, class_names_len))\n",
    "        self.class_classifier.add_module('c_softmax', nn.LogSoftmax(dim=1))\n",
    "\n",
    "        self.domain_classifier = nn.Sequential()\n",
    "        self.domain_classifier.add_module('d_fc1', nn.Linear(self.in_features, 100))\n",
    "        self.domain_classifier.add_module('d_bn1', nn.BatchNorm1d(100))\n",
    "        self.domain_classifier.add_module('d_relu1', nn.ReLU(True))\n",
    "        self.domain_classifier.add_module('d_fc2', nn.Linear(100, 2))\n",
    "        self.domain_classifier.add_module('d_softmax', nn.LogSoftmax(dim=1))\n",
    "\n",
    "    def forward(self, input_data, alpha):\n",
    "        # input_data = input_data.expand(input_data.data.shape[0], 3, 28, 28)\n",
    "        feature = self.feature(input_data)\n",
    "        feature = feature.view(-1, self.in_features)\n",
    "        reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
    "        class_output = self.class_classifier(feature)\n",
    "        domain_output = self.domain_classifier(reverse_feature)\n",
    "\n",
    "        return class_output, domain_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/VIU/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/VIU/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "my_net = CNNModel(class_names_len=len(cataracts_class_names),pretrained_weights='/home/ubuntu/Desktop/Domain_Adaptation_Project/repos/Dann_barlow/pretrained_weights/resnet50.pth')\n",
    "\n",
    "# setup optimizer\n",
    "\n",
    "optimizer = optim.SGD(my_net.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "loss_class = torch.nn.NLLLoss()\n",
    "loss_domain = torch.nn.NLLLoss()\n",
    "\n",
    "my_net = my_net.to(device)\n",
    "loss_class = loss_class.to(device)\n",
    "loss_domain = loss_domain.to(device)\n",
    "\n",
    "for p in my_net.parameters():\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader_source = cataracts_dataloaders\n",
    "# dataloader_target = d99_balanced_dataloaders\n",
    "dataloader_target = cataracts_dataloaders\n",
    "dataloader_source = d99_balanced_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_d99_cat(labels_d99, preds_d99):\n",
    "    labels_99_arr = labels_d99.cpu().numpy()\n",
    "    preds_99_arr = preds_d99.cpu().numpy()\n",
    "    #the keys of this are the labels in the dataset 99 and the values are the corresponding labels in the cataracts dataset\n",
    "    mapper_dict = {\n",
    "        0:12,\n",
    "        1:0,\n",
    "        2:1,\n",
    "        3:11,\n",
    "        4:3,\n",
    "        5:2,\n",
    "        6:5,\n",
    "        7:10,\n",
    "        8:6,\n",
    "        9:8,\n",
    "        10:4,\n",
    "        11:-1,\n",
    "        12:9,\n",
    "        13:-1,\n",
    "        14:-1,\n",
    "        15:-1,\n",
    "        16:-1\n",
    "    } \n",
    "\n",
    "    converted_labels = np.array([mapper_dict[l] for l in labels_99_arr])\n",
    "    valid_idxs = np.where(converted_labels!=-1)[0]\n",
    "    valid_labels = converted_labels[valid_idxs]\n",
    "    valid_preds = preds_99_arr[valid_idxs]\n",
    "    return torch.Tensor(valid_preds), torch.Tensor(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model_path, dataloader, len_classnames, use_dict=False):\n",
    "    my_net = CNNModel(len_classnames)\n",
    "    my_net.load_state_dict(torch.load(model_path))\n",
    "    my_net = my_net.eval()\n",
    "\n",
    "    my_net = my_net.to(device)\n",
    "\n",
    "    len_dataloader = len(dataloader)\n",
    "    data_target_iter = iter(dataloader)\n",
    "\n",
    "    i = 0\n",
    "    n_total = 0\n",
    "    n_correct = 0\n",
    "\n",
    "    while i < len_dataloader:\n",
    "\n",
    "        # test model using target data\n",
    "        data_target = data_target_iter.next()\n",
    "        t_img, t_label = data_target\n",
    "\n",
    "        batch_size = len(t_label)\n",
    "\n",
    "        t_img = t_img.to(device)\n",
    "        t_label = t_label.to(device)\n",
    "\n",
    "        class_output, _ = my_net(input_data=t_img, alpha=0)\n",
    "        pred = class_output.data.max(1, keepdim=True)[1]\n",
    "\n",
    "        if use_dict:\n",
    "            valid_pred, valid_label = mapper_d99_cat(t_label, pred)\n",
    "        else:\n",
    "            valid_pred, valid_label = t_label, pred\n",
    "            \n",
    "        n_correct += valid_pred.eq(valid_label.data.view_as(valid_pred)).cpu().sum()\n",
    "        # print(valid_label.size(dim=0))\n",
    "        n_total += int(valid_label.size(dim=0))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    accu = n_correct.data.numpy() * 1.0 / n_total\n",
    "\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load any existing weights\n",
    "# load_path = '/home/ubuntu/Desktop/Domain_Adaptation_Project/repos/Dann_barlow/pretrained_weights/resnet50.pth'\n",
    "# load_path = '/home/ubuntu/Desktop/Domain_Adaptation_Project/repos/Dann_barlow/saved_models/src_cata_tgt_d99_model_epoch_current_train_pretrain_bt.pth'\n",
    "# my_net.load_state_dict(torch.load(load_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 0, [iter: 277 / all 277], err_s_label: 2.105868, err_s_domain: 0.647139, err_t_domain: 0.665206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/VIU/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the cataracts dataset: 0.309798\n",
      "Accuracy of the dataset99 balanced dataset: 0.182143\n",
      "\n",
      "best source acc:  0.3097978227060653\n",
      "best target acc:  0.18214285714285713\n",
      " epoch: 1, [iter: 277 / all 277], err_s_label: 1.630829, err_s_domain: 0.560050, err_t_domain: 0.498019\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.401555\n",
      "Accuracy of the dataset99 balanced dataset: 0.238690\n",
      "\n",
      "best source acc:  0.4015552099533437\n",
      "best target acc:  0.2386904761904762\n",
      " epoch: 2, [iter: 277 / all 277], err_s_label: 1.189171, err_s_domain: 0.441395, err_t_domain: 0.449658\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.420218\n",
      "Accuracy of the dataset99 balanced dataset: 0.211310\n",
      "\n",
      "best source acc:  0.4015552099533437\n",
      "best target acc:  0.2386904761904762\n",
      " epoch: 3, [iter: 277 / all 277], err_s_label: 0.849641, err_s_domain: 0.259574, err_t_domain: 0.146070\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.429549\n",
      "Accuracy of the dataset99 balanced dataset: 0.235119\n",
      "\n",
      "best source acc:  0.4015552099533437\n",
      "best target acc:  0.2386904761904762\n",
      " epoch: 4, [iter: 277 / all 277], err_s_label: 1.390920, err_s_domain: 0.345306, err_t_domain: 0.133099\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.463453\n",
      "Accuracy of the dataset99 balanced dataset: 0.231548\n",
      "\n",
      "best source acc:  0.4015552099533437\n",
      "best target acc:  0.2386904761904762\n",
      " epoch: 5, [iter: 277 / all 277], err_s_label: 0.558113, err_s_domain: 0.295475, err_t_domain: 0.561954\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.458787\n",
      "Accuracy of the dataset99 balanced dataset: 0.219048\n",
      "\n",
      "best source acc:  0.4015552099533437\n",
      "best target acc:  0.2386904761904762\n",
      " epoch: 6, [iter: 277 / all 277], err_s_label: 1.303266, err_s_domain: 0.488248, err_t_domain: 0.193908\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.480560\n",
      "Accuracy of the dataset99 balanced dataset: 0.253571\n",
      "\n",
      "best source acc:  0.48055987558320373\n",
      "best target acc:  0.25357142857142856\n",
      " epoch: 7, [iter: 277 / all 277], err_s_label: 0.270940, err_s_domain: 0.362413, err_t_domain: 0.152321\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.484603\n",
      "Accuracy of the dataset99 balanced dataset: 0.217262\n",
      "\n",
      "best source acc:  0.48055987558320373\n",
      "best target acc:  0.25357142857142856\n",
      " epoch: 8, [iter: 277 / all 277], err_s_label: 0.878892, err_s_domain: 0.326315, err_t_domain: 0.102789\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.471540\n",
      "Accuracy of the dataset99 balanced dataset: 0.254762\n",
      "\n",
      "best source acc:  0.47153965785381025\n",
      "best target acc:  0.25476190476190474\n",
      " epoch: 9, [iter: 277 / all 277], err_s_label: 0.718690, err_s_domain: 0.119256, err_t_domain: 0.107932\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.483981\n",
      "Accuracy of the dataset99 balanced dataset: 0.279167\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 10, [iter: 277 / all 277], err_s_label: 0.358733, err_s_domain: 0.058162, err_t_domain: 0.146314\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.482115\n",
      "Accuracy of the dataset99 balanced dataset: 0.263690\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 11, [iter: 277 / all 277], err_s_label: 0.784362, err_s_domain: 0.188311, err_t_domain: 0.034677\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.460964\n",
      "Accuracy of the dataset99 balanced dataset: 0.257143\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 12, [iter: 277 / all 277], err_s_label: 0.459517, err_s_domain: 0.099272, err_t_domain: 0.026699\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.488647\n",
      "Accuracy of the dataset99 balanced dataset: 0.238690\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 13, [iter: 277 / all 277], err_s_label: 0.095713, err_s_domain: 0.024569, err_t_domain: 0.020892\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.471851\n",
      "Accuracy of the dataset99 balanced dataset: 0.258333\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 14, [iter: 277 / all 277], err_s_label: 0.076829, err_s_domain: 0.287511, err_t_domain: 0.049227\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.478072\n",
      "Accuracy of the dataset99 balanced dataset: 0.245833\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 15, [iter: 277 / all 277], err_s_label: 0.538805, err_s_domain: 0.034756, err_t_domain: 0.015488\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.484603\n",
      "Accuracy of the dataset99 balanced dataset: 0.270238\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 16, [iter: 277 / all 277], err_s_label: 0.116944, err_s_domain: 0.087805, err_t_domain: 0.036999\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.485848\n",
      "Accuracy of the dataset99 balanced dataset: 0.254762\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 17, [iter: 277 / all 277], err_s_label: 0.184947, err_s_domain: 0.010371, err_t_domain: 0.006849\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.483670\n",
      "Accuracy of the dataset99 balanced dataset: 0.235714\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 18, [iter: 277 / all 277], err_s_label: 0.128457, err_s_domain: 0.028697, err_t_domain: 0.113284\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.483670\n",
      "Accuracy of the dataset99 balanced dataset: 0.250000\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 19, [iter: 277 / all 277], err_s_label: 0.110792, err_s_domain: 0.077563, err_t_domain: 0.005320\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.480871\n",
      "Accuracy of the dataset99 balanced dataset: 0.261310\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 20, [iter: 277 / all 277], err_s_label: 0.306289, err_s_domain: 0.034022, err_t_domain: 0.007393\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.488958\n",
      "Accuracy of the dataset99 balanced dataset: 0.237500\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 21, [iter: 277 / all 277], err_s_label: 0.064017, err_s_domain: 0.136070, err_t_domain: 0.096095\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.484914\n",
      "Accuracy of the dataset99 balanced dataset: 0.261905\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 22, [iter: 277 / all 277], err_s_label: 0.277492, err_s_domain: 0.039069, err_t_domain: 0.058785\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.496423\n",
      "Accuracy of the dataset99 balanced dataset: 0.260714\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 23, [iter: 277 / all 277], err_s_label: 0.091527, err_s_domain: 0.170776, err_t_domain: 0.005336\n",
      "\n",
      "Accuracy of the cataracts dataset: 0.500778\n",
      "Accuracy of the dataset99 balanced dataset: 0.258333\n",
      "\n",
      "best source acc:  0.4839813374805599\n",
      "best target acc:  0.2791666666666667\n",
      " epoch: 24, [iter: 145 / all 277], err_s_label: 0.044956, err_s_domain: 0.016371, err_t_domain: 0.004534"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/Desktop/Domain_Adaptation_Project/repos/mycode/dann.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Domain_Adaptation_Project/repos/mycode/dann.ipynb#ch0000014?line=49'>50</a>\u001b[0m err\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Domain_Adaptation_Project/repos/mycode/dann.ipynb#ch0000014?line=50'>51</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Domain_Adaptation_Project/repos/mycode/dann.ipynb#ch0000014?line=52'>53</a>\u001b[0m sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m epoch: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, [iter: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m / all \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m], err_s_label: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m, err_s_domain: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m, err_t_domain: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m'\u001b[39m \\\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Domain_Adaptation_Project/repos/mycode/dann.ipynb#ch0000014?line=53'>54</a>\u001b[0m       \u001b[39m%\u001b[39m (epoch, i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, len_dataloader, err_s_label\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Domain_Adaptation_Project/repos/mycode/dann.ipynb#ch0000014?line=54'>55</a>\u001b[0m          err_s_domain\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy(), err_t_domain\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Domain_Adaptation_Project/repos/mycode/dann.ipynb#ch0000014?line=55'>56</a>\u001b[0m sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mflush()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Domain_Adaptation_Project/repos/mycode/dann.ipynb#ch0000014?line=57'>58</a>\u001b[0m torch\u001b[39m.\u001b[39msave(my_net\u001b[39m.\u001b[39mstate_dict(), save_path)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "save_path = './src_d99_tgt_cata_model_simpleDann_current.pth'\n",
    "best_accu_t = 0.0\n",
    "for epoch in range(n_epoch):\n",
    "\n",
    "    len_dataloader = min(len(dataloader_source['train']), len(dataloader_target['train']))\n",
    "    data_source_iter = iter(dataloader_source['train'])\n",
    "    data_target_iter = iter(dataloader_target['train'])\n",
    "\n",
    "    for i in range(len_dataloader):\n",
    "\n",
    "        p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n",
    "        # alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "        alpha = 0.5\n",
    "        # print(alpha)\n",
    "\n",
    "        # training model using source data\n",
    "        data_source = data_source_iter.next()\n",
    "        s_img, s_label = data_source\n",
    "\n",
    "        my_net.zero_grad()\n",
    "        batch_size = len(s_label)\n",
    "\n",
    "        domain_label = torch.zeros(batch_size).long()\n",
    "\n",
    "\n",
    "        s_img = s_img.to(device)\n",
    "        s_label = s_label.to(device)\n",
    "        domain_label = domain_label.to(device)\n",
    "\n",
    "\n",
    "        class_output, domain_output = my_net(input_data=s_img, alpha=alpha)\n",
    "        err_s_label = loss_class(class_output, s_label)\n",
    "        err_s_domain = loss_domain(domain_output, domain_label)\n",
    "\n",
    "        # training model using target data\n",
    "        data_target = data_target_iter.next()\n",
    "        t_img, _ = data_target\n",
    "\n",
    "        batch_size = len(t_img)\n",
    "\n",
    "        domain_label = torch.ones(batch_size).long()\n",
    "\n",
    "        t_img = t_img.to(device)\n",
    "        domain_label = domain_label.to(device)\n",
    "\n",
    "        _, domain_output = my_net(input_data=t_img, alpha=alpha)\n",
    "        err_t_domain = loss_domain(domain_output, domain_label)\n",
    "        err = err_t_domain + err_s_domain + err_s_label\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sys.stdout.write('\\r epoch: %d, [iter: %d / all %d], err_s_label: %f, err_s_domain: %f, err_t_domain: %f' \\\n",
    "              % (epoch, i + 1, len_dataloader, err_s_label.data.cpu().numpy(),\n",
    "                 err_s_domain.data.cpu().numpy(), err_t_domain.data.cpu().item()))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        torch.save(my_net.state_dict(), save_path)\n",
    "\n",
    "    print('\\n')\n",
    "    accu_s = test(save_path, dataloader_source['val'],len(cataracts_class_names))\n",
    "    print('Accuracy of the %s dataset: %f' % ('cataracts', accu_s))\n",
    "    accu_t = test(save_path,dataloader_target['val'],len(cataracts_class_names))\n",
    "    print('Accuracy of the %s dataset: %f\\n' % ('dataset99 balanced', accu_t))\n",
    "    if accu_t > best_accu_t:\n",
    "        best_accu_s = accu_s\n",
    "        best_accu_t = accu_t\n",
    "        torch.save(my_net.state_dict(), './src_cata_tgt_d99_model_epoch_best.pth')\n",
    "\n",
    "    print(\"best source acc: \",best_accu_s)\n",
    "    print(\"best target acc: \",best_accu_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('VIU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4126c241b84f5889e75cbd84fa6f043385354e2d4f40a3ac9b085c062df1b4e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
